{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1a6282e-adcb-43da-9339-a17ca566a62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sodapy import Socrata\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16d8b8b7-f62e-4ec5-a7cf-f4525d8c6baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfp = dd.read_parquet('cdc_data.parquet.gzip')\n",
    "# dfh = dd.read_hdf('cdc_data_comp.h5', key='pm')\n",
    "# dfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9acdff5a-0d02-4350-960a-0fa70f967b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_cdc_dtypes(df):\n",
    "    \"\"\"\n",
    "    optimize dtypes for raw data returned from\n",
    "    CDC SODA API call.\n",
    "    input is pandas df of raw records from API\n",
    "    output is pandas df with optimized dtypes\n",
    "    \"\"\"\n",
    "    \n",
    "    # Print starting memory size\n",
    "    start_size = df.memory_usage(index=True, deep=True) / (1024**2)\n",
    "    start_size = np.round(start_size.sum, 3)\n",
    "    print(f'start size: {start_size} MB')\n",
    "    \n",
    "    # Declare df dict\n",
    "    df_dtypes = {\n",
    "        'year': 'int16', # can be dropped\n",
    "        'date': 'category', \n",
    "        'statefips': 'int8', \n",
    "        'countyfips': 'int32', \n",
    "        'ctfips': 'int64', \n",
    "        'latitude': 'float32',\n",
    "        'longitude': 'float32', \n",
    "        'ds_pm_pred': 'float32', \n",
    "        'ds_pm_stdd': 'float32',\n",
    "    }\n",
    "\n",
    "    # Optimize dtypes\n",
    "    for k, v in df_dtypes.items():\n",
    "        if k in results_df.columns:\n",
    "            if k == 'date':\n",
    "                results_df[k] = pd.to_datetime(results_df[k], format='%d%b%Y')\n",
    "            else:\n",
    "                results_df[k] = results_df[k].astype(v)\n",
    "\n",
    "    # Print ending memory size\n",
    "    end_size = df.memory_usage(index=True, deep=True) / (1024**2)\n",
    "    end_size = np.round(end_size.sum, 3)\n",
    "    print(f'end size:   {end_size} MB')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91620c0f-4a46-4015-91ac-ef75ff84b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdc_data_pull(cols=None, filt=None, writeout=True):\n",
    "    \"\"\"\n",
    "    reads PM data from CDC into memory. data from:\n",
    "    https://data.cdc.gov/Environmental-Health-Toxicology/Daily-Census-Tract-Level-PM2-5-Concentrations-2011/fcqm-xrf4\n",
    "\n",
    "    pulls PM data from CDC SODA API if not locally found,\n",
    "    else reads it in\n",
    "    \n",
    "    inputs:\n",
    "        - cols: list, list of strings of col names to query\n",
    "        - filt: str, SQL-like string to pass as WHERE clause to query\n",
    "        - writeout: bool, whether to write df to disk\n",
    "    output is dask dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    # Declare SQL-like args to pass to SODA API\n",
    "    # State FIPS filter gets data for California, Texas, and Illinois\n",
    "    if pd.isnull(cols):\n",
    "        cols = \"date, statefips, countyfips, ctfips, ds_pm_pred, ds_pm_stdd\"\n",
    "    if pd.isnull(filt):\n",
    "        filt = \"year = '2014' AND statefips IN ('6', '48', '17')\" \n",
    "\n",
    "    # Establish SODA client via sodapy wrapper (using Socrata class)\n",
    "    # Sodapy notes:\n",
    "    # \"Unauthenticated client only works with public data sets. Note 'None'\n",
    "    # in place of application token, and no username or password:\"\n",
    "    client = Socrata(\"data.cdc.gov\", None)\n",
    "\n",
    "    # Get queried data subset from CDC SODA API\n",
    "    records = client.get(\"fcqm-xrf4\", select=cols, where=filt, limit=10000000)\n",
    "\n",
    "    client.close() # close connection\n",
    "\n",
    "    # Convert to pandas DataFrame\n",
    "    df = pd.DataFrame.from_records(records)\n",
    "    \n",
    "    # Optimize dtypes to minimize size in RAM\n",
    "    df = optimize_cdc_dtypes(df)\n",
    "    \n",
    "    # Convert to dask dataframe\n",
    "    ddf = dd.from_pandas(df, npartitions=60) # of ~100,000 rows each\n",
    "    \n",
    "    if writeout:\n",
    "        # Write to disk\n",
    "        # ddf.to_parquet('cdc_data.parquet.gzip', compression='gzip')\n",
    "        ddf.to_hdf('cdc_data_comp.h5', key='pm', complib='lzo', complevel=1, format='table')\n",
    "        \n",
    "    return ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddc86ca2-5d6f-4df8-8d70-d7370e74e8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdc_data_gen(fpath='', cols=None, filt=None, writeout=True):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if len(fpath)==0:\n",
    "        ddf = cdc_data_pull(cols, filt, writeout)\n",
    "    else:\n",
    "        ddf = dd.read_hdf('cdc_data_comp.h5', key='pm')\n",
    "    return ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6978e398-219e-4fa1-b1dc-4c32efc552a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython - invlyr",
   "language": "python",
   "name": "invlyr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
